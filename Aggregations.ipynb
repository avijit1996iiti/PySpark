{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7646e24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/07 09:10:41 WARN Utils: Your hostname, avijit-HP-Laptop-15q-bu0xx resolves to a loopback address: 127.0.1.1; using 192.168.18.7 instead (on interface wlo1)\n",
      "23/03/07 09:10:41 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/07 09:10:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Avi').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1acefd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "retail_df = spark.read.format('csv').option('inferSchema',\"True\").option(\"header\",'true').load(\"./data/retail_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "407ceb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|   InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|12/01/10 08:26|     2.55|     17850|United Kingdom|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|12/01/10 08:26|     3.39|     17850|United Kingdom|\n",
      "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retail_df.show(2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a870f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "541909"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retail_df.count() # Here Count is used as an action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15034ea4",
   "metadata": {},
   "source": [
    "# Count() as a transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba2f06d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|count(StockCode)|\n",
      "+----------------+\n",
      "|          541909|\n",
      "+----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 10:===========================================>              (3 + 1) / 4]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count\n",
    "retail_df.select(count(\"StockCode\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dbc1d1",
   "metadata": {},
   "source": [
    "when performing count(*) spark will count all null values, however when counting an individual column spark will not count the null values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d5aa8b",
   "metadata": {},
   "source": [
    "# Number of distinct groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b978aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avijit/.local/lib/python3.8/site-packages/pyspark/sql/functions.py:316: FutureWarning: Deprecated in 3.2, use sum_distinct instead.\n",
      "  warnings.warn(\"Deprecated in 3.2, use sum_distinct instead.\", FutureWarning)\n",
      "[Stage 13:>                                                         (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|sum(DISTINCT Quantity)|\n",
      "+----------------------+\n",
      "|                 29310|\n",
      "+----------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sumDistinct\n",
    "retail_df.select(sumDistinct(\"Quantity\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da916ef",
   "metadata": {},
   "source": [
    "# avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a55e64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum, count, avg, expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c896bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------+----------------+----------------+\n",
      "|(total_purchases / total_transanctions)|   avg_purchases|  mean_purchases|\n",
      "+---------------------------------------+----------------+----------------+\n",
      "|                       9.55224954743324|9.55224954743324|9.55224954743324|\n",
      "+---------------------------------------+----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retail_df.select(\n",
    "count('Quantity').alias(\"total_transanctions\"),\n",
    "sum(\"Quantity\").alias(\"total_purchases\"),\n",
    "avg(\"Quantity\").alias(\"avg_purchases\"),\n",
    "expr(\"mean(Quantity)\").alias(\"mean_purchases\")\n",
    ").selectExpr(\n",
    "    \"total_purchases/total_transanctions\",\n",
    "    \"avg_purchases\",\n",
    "    \"mean_purchases\"\n",
    "    \n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efef7fb3",
   "metadata": {},
   "source": [
    "# Aggregating to Complex types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44d9f3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import collect_set,collect_list\n",
    "a_= retail_df.agg(collect_set(\"Country\"),collect_list(\"Country\")).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e540f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "541909"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a_[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae1b2bf",
   "metadata": {},
   "source": [
    "# Grouping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "751d7778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-----+\n",
      "|InvoiceNo|CustomerId|count|\n",
      "+---------+----------+-----+\n",
      "|   536846|     14573|   76|\n",
      "|   537026|     12395|   12|\n",
      "+---------+----------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retail_df.groupBy(\"InvoiceNo\",\"CustomerId\").count().show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372dee24",
   "metadata": {},
   "source": [
    "# grouping with maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e323d75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 40:>                                                         (0 + 4) / 4]\r",
      "\r",
      "[Stage 40:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+--------------------+\n",
      "|InvoiceNo|     avg(Quantity)|stddev_pop(Quantity)|\n",
      "+---------+------------------+--------------------+\n",
      "|   536596|               1.5|  1.1180339887498947|\n",
      "|   536938|33.142857142857146|  20.698023172885524|\n",
      "|   537252|              31.0|                 0.0|\n",
      "|   537691|              8.15|   5.597097462078001|\n",
      "|   538041|              30.0|                 0.0|\n",
      "|   538184|12.076923076923077|   8.142590198943392|\n",
      "|   538517|3.0377358490566038|  2.3946659604837897|\n",
      "|   538879|21.157894736842106|  11.811070444356483|\n",
      "|   539275|              26.0|  12.806248474865697|\n",
      "|   539630|20.333333333333332|  10.225241100118645|\n",
      "|   540499|              3.75|  2.6653642652865788|\n",
      "|   540540|2.1363636363636362|  1.0572457590557278|\n",
      "|  C540850|              -1.0|                 0.0|\n",
      "|   540976|10.520833333333334|   6.496760677872902|\n",
      "|   541432|             12.25|  10.825317547305483|\n",
      "|   541518| 23.10891089108911|  20.550782784878713|\n",
      "|   541783|11.314285714285715|   8.467657556242811|\n",
      "|   542026| 7.666666666666667|   4.853406592853679|\n",
      "|   542375|               8.0|  3.4641016151377544|\n",
      "|  C542604|              -8.0|  15.173990905493518|\n",
      "+---------+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "retail_df.groupBy(\"InvoiceNo\").agg(expr(\"avg(Quantity)\"),expr(\"stddev_pop(Quantity)\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d76ea35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
