{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ed5b306",
   "metadata": {},
   "source": [
    "# Join Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221f593b",
   "metadata": {},
   "source": [
    "It determines whether Spark should bring together the left set of data with right set of data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1babb02a",
   "metadata": {},
   "source": [
    "# Join Types "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9847786b",
   "metadata": {},
   "source": [
    "It Determines what should be in the result set "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d030f5b",
   "metadata": {},
   "source": [
    "- Inner Joins \n",
    "- Outer Joins\n",
    "- Left Outer Joins\n",
    "- Right Outer Joins\n",
    "- Left Semi Joins\n",
    "- Left Anti Joins\n",
    "- Natural Joins\n",
    "- Cross Joins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c062b20",
   "metadata": {},
   "source": [
    "# Create Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f5644bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/11 18:03:56 WARN Utils: Your hostname, avijit-HP-Laptop-15q-bu0xx resolves to a loopback address: 127.0.1.1; using 192.168.18.7 instead (on interface wlo1)\n",
      "23/03/11 18:03:56 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/11 18:04:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Avi').master('local').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4052c244",
   "metadata": {},
   "source": [
    "# # Create Dataframes required for the illustration purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f66f429",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_df = spark.createDataFrame(\n",
    "[\n",
    "    (0,\"Avijit\",0,[100]),\n",
    "    (1,\"Avik\",1,[500,250,100]),\n",
    "    (2,\"Sudipto\",1,[250,100])\n",
    "]\n",
    ").toDF(\"id\",\"name\",\"graduate_program\",\"spark_status\")\n",
    "\n",
    "graduate_program_df = spark.createDataFrame(\n",
    "[\n",
    "    (0,\"Masters\",\"Mathematics\",\"IIT Indore\"),\n",
    "    (2,\"Masters\",\"Physics\",\"IIT Indore\"),\n",
    "    (1,\"Ph.d\",\"Physics\",\"IIT Indore\")\n",
    "]).toDF(\"id\",\"degree\",\"department\",\"school\")\n",
    "\n",
    "spark_status_df = spark.createDataFrame([\n",
    "    (500,\"Vice President\"),\n",
    "    (250,\"PMC Member\"),\n",
    "    (100,\"Contributor\")\n",
    "    \n",
    "]).toDF(\"id\",\"Status\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9291aee3",
   "metadata": {},
   "source": [
    "# Register these as sql tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92f8b7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_df.createOrReplaceTempView(\"person_table\")\n",
    "graduate_program_df.createOrReplaceTempView(\"graduate_program_table\")\n",
    "spark_status_df.createOrReplaceTempView(\"spark_status_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afb1a76",
   "metadata": {},
   "source": [
    "# Inner Join\n",
    "\n",
    "It evaluates keys in both dataframe or tables and include only rows that evaluate to true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8d56e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----------------+---------------+---+-------+-----------+----------+\n",
      "| id|   name|graduate_program|   spark_status| id| degree| department|    school|\n",
      "+---+-------+----------------+---------------+---+-------+-----------+----------+\n",
      "|  0| Avijit|               0|          [100]|  0|Masters|Mathematics|IIT Indore|\n",
      "|  1|   Avik|               1|[500, 250, 100]|  1|   Ph.d|    Physics|IIT Indore|\n",
      "|  2|Sudipto|               1|     [250, 100]|  1|   Ph.d|    Physics|IIT Indore|\n",
      "+---+-------+----------------+---------------+---+-------+-----------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT * FROM person_table\n",
    "INNER JOIN graduate_program_table\n",
    "ON person_table.graduate_program = graduate_program_table.id\n",
    "\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21f9b8d",
   "metadata": {},
   "source": [
    "# Outer Join\n",
    "It evaluate the keys in both of the dataframes or tables and includes the rows that evaluate to true or false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6df4b65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+----------------+---------------+---+-------+-----------+----------+\n",
      "|  id|   name|graduate_program|   spark_status| id| degree| department|    school|\n",
      "+----+-------+----------------+---------------+---+-------+-----------+----------+\n",
      "|   0| Avijit|               0|          [100]|  0|Masters|Mathematics|IIT Indore|\n",
      "|   1|   Avik|               1|[500, 250, 100]|  1|   Ph.d|    Physics|IIT Indore|\n",
      "|   2|Sudipto|               1|     [250, 100]|  1|   Ph.d|    Physics|IIT Indore|\n",
      "|null|   null|            null|           null|  2|Masters|    Physics|IIT Indore|\n",
      "+----+-------+----------------+---------------+---+-------+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT * FROM person_table\n",
    "FULL OUTER JOIN graduate_program_table\n",
    "ON person_table.graduate_program = graduate_program_table.id\n",
    "\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfb227b",
   "metadata": {},
   "source": [
    "# Left Outer Join\n",
    "evaluate the keys in both dataframes or tables and includes all rows from the left dataframe as well as any rows in the right dataframe that have a match in the left dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ca37207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----------------+---------------+---+-------+-----------+----------+\n",
      "| id|   name|graduate_program|   spark_status| id| degree| department|    school|\n",
      "+---+-------+----------------+---------------+---+-------+-----------+----------+\n",
      "|  0| Avijit|               0|          [100]|  0|Masters|Mathematics|IIT Indore|\n",
      "|  1|   Avik|               1|[500, 250, 100]|  1|   Ph.d|    Physics|IIT Indore|\n",
      "|  2|Sudipto|               1|     [250, 100]|  1|   Ph.d|    Physics|IIT Indore|\n",
      "+---+-------+----------------+---------------+---+-------+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT * FROM person_table\n",
    "LEFT OUTER JOIN graduate_program_table\n",
    "ON person_table.graduate_program = graduate_program_table.id\n",
    "\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fd823b",
   "metadata": {},
   "source": [
    "# Right Outer Join\n",
    "evaluate the keys in both dataframes or tables and includes all rows from the right dataframe as well as any rows in the left dataframe that have a match in the right dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7242b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+----------------+---------------+---+-------+-----------+----------+\n",
      "|  id|   name|graduate_program|   spark_status| id| degree| department|    school|\n",
      "+----+-------+----------------+---------------+---+-------+-----------+----------+\n",
      "|   0| Avijit|               0|          [100]|  0|Masters|Mathematics|IIT Indore|\n",
      "|   2|Sudipto|               1|     [250, 100]|  1|   Ph.d|    Physics|IIT Indore|\n",
      "|   1|   Avik|               1|[500, 250, 100]|  1|   Ph.d|    Physics|IIT Indore|\n",
      "|null|   null|            null|           null|  2|Masters|    Physics|IIT Indore|\n",
      "+----+-------+----------------+---------------+---+-------+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT * FROM person_table\n",
    "RIGHT OUTER JOIN graduate_program_table\n",
    "ON person_table.graduate_program = graduate_program_table.id\n",
    "\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6baac3",
   "metadata": {},
   "source": [
    "#  Left Semi Join\n",
    "\n",
    "Semi joins are bit of departure from other joins. They do not actually include any values from the right dataframe. They only compare values to see if the values exist in the right dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baa8da35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----------------+---------------+\n",
      "| id|   name|graduate_program|   spark_status|\n",
      "+---+-------+----------------+---------------+\n",
      "|  0| Avijit|               0|          [100]|\n",
      "|  1|   Avik|               1|[500, 250, 100]|\n",
      "|  2|Sudipto|               1|     [250, 100]|\n",
      "+---+-------+----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT * FROM person_table\n",
    "LEFT SEMI JOIN graduate_program_table\n",
    "ON person_table.graduate_program = graduate_program_table.id\n",
    "\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49844e7",
   "metadata": {},
   "source": [
    "#  Left Anti Join\n",
    "\n",
    "Left Anti Joins are opposite of left semi joins. Rather than keeping the values that exist in second dataframe,\n",
    "they keep only values that do not have corresponding key in second dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff400c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+----------------+------------+\n",
      "| id|name|graduate_program|spark_status|\n",
      "+---+----+----------------+------------+\n",
      "+---+----+----------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT * FROM person_table\n",
    "LEFT ANTI JOIN graduate_program_table\n",
    "ON person_table.graduate_program = graduate_program_table.id\n",
    "\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd7f8ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----------+----------+\n",
      "| id| degree|department|    school|\n",
      "+---+-------+----------+----------+\n",
      "|  2|Masters|   Physics|IIT Indore|\n",
      "+---+-------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT * FROM graduate_program_table\n",
    "LEFT ANTI JOIN person_table\n",
    "ON person_table.graduate_program = graduate_program_table.id\n",
    "\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c100bb",
   "metadata": {},
   "source": [
    "# Natural Joins\n",
    "It makes implicit guess on the columns on which you would like to join. It finds the matching columns and returns the results "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff523c47",
   "metadata": {},
   "source": [
    "# Cross Joins\n",
    "In simplest terms cross joins are inner joins that do not specify a predicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea5d61cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----------------+---------------+---+-------+-----------+----------+\n",
      "| id|   name|graduate_program|   spark_status| id| degree| department|    school|\n",
      "+---+-------+----------------+---------------+---+-------+-----------+----------+\n",
      "|  0| Avijit|               0|          [100]|  0|Masters|Mathematics|IIT Indore|\n",
      "|  0| Avijit|               0|          [100]|  2|Masters|    Physics|IIT Indore|\n",
      "|  0| Avijit|               0|          [100]|  1|   Ph.d|    Physics|IIT Indore|\n",
      "|  1|   Avik|               1|[500, 250, 100]|  0|Masters|Mathematics|IIT Indore|\n",
      "|  1|   Avik|               1|[500, 250, 100]|  2|Masters|    Physics|IIT Indore|\n",
      "|  1|   Avik|               1|[500, 250, 100]|  1|   Ph.d|    Physics|IIT Indore|\n",
      "|  2|Sudipto|               1|     [250, 100]|  0|Masters|Mathematics|IIT Indore|\n",
      "|  2|Sudipto|               1|     [250, 100]|  2|Masters|    Physics|IIT Indore|\n",
      "|  2|Sudipto|               1|     [250, 100]|  1|   Ph.d|    Physics|IIT Indore|\n",
      "+---+-------+----------------+---------------+---+-------+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT * FROM person_table\n",
    "CROSS JOIN graduate_program_table\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "051402d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----------------+---------------+---+-------+-----------+----------+\n",
      "| id|   name|graduate_program|   spark_status| id| degree| department|    school|\n",
      "+---+-------+----------------+---------------+---+-------+-----------+----------+\n",
      "|  0| Avijit|               0|          [100]|  0|Masters|Mathematics|IIT Indore|\n",
      "|  1|   Avik|               1|[500, 250, 100]|  1|   Ph.d|    Physics|IIT Indore|\n",
      "|  2|Sudipto|               1|     [250, 100]|  1|   Ph.d|    Physics|IIT Indore|\n",
      "+---+-------+----------------+---------------+---+-------+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT * FROM person_table\n",
    "CROSS JOIN graduate_program_table\n",
    "ON person_table.graduate_program = graduate_program_table.id\n",
    "\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50afacf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
